{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T10:21:37.623679Z",
     "start_time": "2019-06-30T10:21:37.385149Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#from pytorch_edgeml.graph.protoNN import ProtoNN\n",
    "#from pytorch_edgeml.trainer.protoNNTrainer import ProtoNNTrainer\n",
    "from protoNN_local import ProtoNN\n",
    "from protoNNTrainer_local import ProtoNNTrainer\n",
    "import utils_local as utils\n",
    "import helpermethods as helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USPS Data\n",
    "It is assumed that the USPS data has already been downloaded and set up with the help of `fetch_usps.py` and is placed in the `./usps10` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T10:21:37.643781Z",
     "start_time": "2019-06-30T10:21:37.626020Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "DATA_DIR = './usps10'\n",
    "train, test = np.load(DATA_DIR + '/train.npy'), np.load(DATA_DIR + '/test.npy')\n",
    "x_train, y_train = train[:, 1:], train[:, 0]\n",
    "x_test, y_test = test[:, 1:], test[:, 0]\n",
    "\n",
    "numClasses = max(y_train) - min(y_train) + 1\n",
    "numClasses = max(numClasses, max(y_test) - min(y_test) + 1)\n",
    "numClasses = int(numClasses)\n",
    "\n",
    "y_train = helper.to_onehot(y_train, numClasses)\n",
    "y_test = helper.to_onehot(y_test, numClasses)\n",
    "dataDimension = x_train.shape[1]\n",
    "numClasses = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters\n",
    "\n",
    "Note that ProtoNN is very sensitive to the value of the hyperparameter $\\gamma$, here stored in valiable GAMMA. If GAMMA is set to None, median heuristic will be used to estimate a good value of $\\gamma$ through the helper.getGamma() method. This method also returns the corresponding W and B matrices which should be used to initialize ProtoNN (as is done here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T10:21:37.653094Z",
     "start_time": "2019-06-30T10:21:37.645811Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECTION_DIM = 60\n",
    "NUM_PROTOTYPES = 60\n",
    "REG_W = 0.000005\n",
    "REG_B = 0.0\n",
    "REG_Z = 0.00005\n",
    "SPAR_W = 0.8\n",
    "SPAR_B = 1.0\n",
    "SPAR_Z = 1.0\n",
    "LEARNING_RATE = 0.05\n",
    "NUM_EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T10:21:37.680649Z",
     "start_time": "2019-06-30T10:21:37.654776Z"
    }
   },
   "outputs": [],
   "source": [
    "W, B, gamma = helper.getGamma(GAMMA, PROJECTION_DIM, dataDimension,\n",
    "                       NUM_PROTOTYPES, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T10:21:37.700092Z",
     "start_time": "2019-06-30T10:21:37.682341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using x-entropy loss\n"
     ]
    }
   ],
   "source": [
    "protoNNObj = ProtoNN(dataDimension, PROJECTION_DIM, NUM_PROTOTYPES, numClasses,\n",
    "                     gamma, W=W, B=B)\n",
    "protoNNTrainer = ProtoNNTrainer(protoNNObj, REG_W, REG_B, REG_Z, SPAR_W, SPAR_B, SPAR_W,\n",
    "                                LEARNING_RATE, lossType='xentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T10:25:13.443873Z",
     "start_time": "2019-06-30T10:21:37.702352Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 batch 0 loss 13.823788 acc 0.125000\n",
      "Epoch 1 batch 0 loss 1.719323 acc 0.500000\n",
      "Epoch 2 batch 0 loss 1.131474 acc 0.687500\n",
      "Epoch 3 batch 0 loss 0.733530 acc 0.843750\n",
      "Epoch 4 batch 0 loss 0.612357 acc 0.906250\n",
      "Epoch 5 batch 0 loss 0.562658 acc 0.875000\n",
      "Epoch 6 batch 0 loss 0.512034 acc 0.906250\n",
      "Epoch 7 batch 0 loss 0.479914 acc 0.937500\n",
      "Epoch 8 batch 0 loss 0.447306 acc 0.937500\n",
      "Epoch 9 batch 0 loss 0.422184 acc 0.937500\n",
      "Validation accuracy: 0.871450\n",
      "Epoch 10 batch 0 loss 0.402824 acc 0.937500\n",
      "Epoch 11 batch 0 loss 0.388065 acc 0.937500\n",
      "Epoch 12 batch 0 loss 0.376297 acc 0.937500\n",
      "Epoch 13 batch 0 loss 0.370000 acc 0.937500\n",
      "Epoch 14 batch 0 loss 0.366555 acc 0.906250\n",
      "Epoch 15 batch 0 loss 0.361238 acc 0.906250\n",
      "Epoch 16 batch 0 loss 0.359067 acc 0.937500\n",
      "Epoch 17 batch 0 loss 0.359318 acc 0.937500\n",
      "Epoch 18 batch 0 loss 0.358350 acc 0.937500\n",
      "Epoch 19 batch 0 loss 0.365270 acc 0.937500\n",
      "Validation accuracy: 0.887892\n",
      "Epoch 20 batch 0 loss 0.367148 acc 0.937500\n",
      "Epoch 21 batch 0 loss 0.373117 acc 0.937500\n",
      "Epoch 22 batch 0 loss 0.366033 acc 0.937500\n",
      "Epoch 23 batch 0 loss 0.373430 acc 0.937500\n",
      "Epoch 24 batch 0 loss 0.376971 acc 0.937500\n",
      "Epoch 25 batch 0 loss 0.376261 acc 0.937500\n",
      "Epoch 26 batch 0 loss 0.383174 acc 0.937500\n",
      "Epoch 27 batch 0 loss 0.384468 acc 0.937500\n",
      "Epoch 28 batch 0 loss 0.379596 acc 0.937500\n",
      "Epoch 29 batch 0 loss 0.384076 acc 0.937500\n",
      "Validation accuracy: 0.894370\n",
      "Epoch 30 batch 0 loss 0.386359 acc 0.937500\n",
      "Epoch 31 batch 0 loss 0.387035 acc 0.937500\n",
      "Epoch 32 batch 0 loss 0.393278 acc 0.937500\n",
      "Epoch 33 batch 0 loss 0.395854 acc 0.937500\n",
      "Epoch 34 batch 0 loss 0.398426 acc 0.937500\n",
      "Epoch 35 batch 0 loss 0.400290 acc 0.937500\n",
      "Epoch 36 batch 0 loss 0.395880 acc 0.937500\n",
      "Epoch 37 batch 0 loss 0.395766 acc 0.937500\n",
      "Epoch 38 batch 0 loss 0.393812 acc 0.937500\n",
      "Epoch 39 batch 0 loss 0.393922 acc 0.937500\n",
      "Validation accuracy: 0.898854\n",
      "Epoch 40 batch 0 loss 0.391830 acc 0.937500\n",
      "Epoch 41 batch 0 loss 0.388157 acc 0.937500\n",
      "Epoch 42 batch 0 loss 0.383662 acc 0.937500\n",
      "Epoch 43 batch 0 loss 0.378278 acc 0.937500\n",
      "Epoch 44 batch 0 loss 0.374903 acc 0.937500\n",
      "Epoch 45 batch 0 loss 0.371063 acc 0.937500\n",
      "Epoch 46 batch 0 loss 0.363721 acc 0.937500\n",
      "Epoch 47 batch 0 loss 0.359511 acc 0.937500\n",
      "Epoch 48 batch 0 loss 0.355476 acc 0.937500\n",
      "Epoch 49 batch 0 loss 0.350001 acc 0.937500\n",
      "Validation accuracy: 0.898356\n",
      "Epoch 50 batch 0 loss 0.349137 acc 0.937500\n",
      "Epoch 51 batch 0 loss 0.343653 acc 0.937500\n",
      "Epoch 52 batch 0 loss 0.342265 acc 0.937500\n",
      "Epoch 53 batch 0 loss 0.340681 acc 0.937500\n",
      "Epoch 54 batch 0 loss 0.340721 acc 0.937500\n",
      "Epoch 55 batch 0 loss 0.337180 acc 0.937500\n",
      "Epoch 56 batch 0 loss 0.335910 acc 0.937500\n",
      "Epoch 57 batch 0 loss 0.334829 acc 0.937500\n",
      "Epoch 58 batch 0 loss 0.333866 acc 0.937500\n",
      "Epoch 59 batch 0 loss 0.329643 acc 0.937500\n",
      "Validation accuracy: 0.904335\n",
      "Epoch 60 batch 0 loss 0.329313 acc 0.906250\n",
      "Epoch 61 batch 0 loss 0.328109 acc 0.906250\n",
      "Epoch 62 batch 0 loss 0.326589 acc 0.906250\n",
      "Epoch 63 batch 0 loss 0.325893 acc 0.906250\n",
      "Epoch 64 batch 0 loss 0.324960 acc 0.906250\n",
      "Epoch 65 batch 0 loss 0.320161 acc 0.937500\n",
      "Epoch 66 batch 0 loss 0.321494 acc 0.906250\n",
      "Epoch 67 batch 0 loss 0.322442 acc 0.906250\n",
      "Epoch 68 batch 0 loss 0.321416 acc 0.906250\n",
      "Epoch 69 batch 0 loss 0.320882 acc 0.906250\n",
      "Validation accuracy: 0.904335\n",
      "Epoch 70 batch 0 loss 0.318901 acc 0.906250\n",
      "Epoch 71 batch 0 loss 0.317540 acc 0.906250\n",
      "Epoch 72 batch 0 loss 0.317321 acc 0.906250\n",
      "Epoch 73 batch 0 loss 0.316909 acc 0.906250\n",
      "Epoch 74 batch 0 loss 0.316746 acc 0.906250\n",
      "Epoch 75 batch 0 loss 0.318576 acc 0.906250\n",
      "Epoch 76 batch 0 loss 0.319096 acc 0.906250\n",
      "Epoch 77 batch 0 loss 0.318146 acc 0.906250\n",
      "Epoch 78 batch 0 loss 0.319127 acc 0.906250\n",
      "Epoch 79 batch 0 loss 0.318767 acc 0.906250\n",
      "Validation accuracy: 0.905830\n",
      "Epoch 80 batch 0 loss 0.318061 acc 0.906250\n",
      "Epoch 81 batch 0 loss 0.318092 acc 0.906250\n",
      "Epoch 82 batch 0 loss 0.318496 acc 0.906250\n",
      "Epoch 83 batch 0 loss 0.319154 acc 0.906250\n",
      "Epoch 84 batch 0 loss 0.316624 acc 0.906250\n",
      "Epoch 85 batch 0 loss 0.316360 acc 0.906250\n",
      "Epoch 86 batch 0 loss 0.317663 acc 0.906250\n",
      "Epoch 87 batch 0 loss 0.318266 acc 0.906250\n",
      "Epoch 88 batch 0 loss 0.319635 acc 0.906250\n",
      "Epoch 89 batch 0 loss 0.316575 acc 0.906250\n",
      "Validation accuracy: 0.906826\n",
      "Epoch 90 batch 0 loss 0.317286 acc 0.906250\n",
      "Epoch 91 batch 0 loss 0.317063 acc 0.906250\n",
      "Epoch 92 batch 0 loss 0.318056 acc 0.906250\n",
      "Epoch 93 batch 0 loss 0.318002 acc 0.906250\n",
      "Epoch 94 batch 0 loss 0.317221 acc 0.906250\n",
      "Epoch 95 batch 0 loss 0.317108 acc 0.906250\n",
      "Epoch 96 batch 0 loss 0.316980 acc 0.906250\n",
      "Epoch 97 batch 0 loss 0.316897 acc 0.906250\n",
      "Epoch 98 batch 0 loss 0.315639 acc 0.906250\n",
      "Epoch 99 batch 0 loss 0.315733 acc 0.906250\n",
      "Validation accuracy: 0.909816\n",
      "Epoch 100 batch 0 loss 0.315678 acc 0.906250\n",
      "Epoch 101 batch 0 loss 0.315693 acc 0.906250\n",
      "Epoch 102 batch 0 loss 0.315706 acc 0.906250\n",
      "Epoch 103 batch 0 loss 0.315729 acc 0.906250\n",
      "Epoch 104 batch 0 loss 0.315815 acc 0.906250\n",
      "Epoch 105 batch 0 loss 0.314680 acc 0.906250\n",
      "Epoch 106 batch 0 loss 0.315134 acc 0.906250\n",
      "Epoch 107 batch 0 loss 0.313352 acc 0.937500\n",
      "Epoch 108 batch 0 loss 0.312858 acc 0.937500\n",
      "Epoch 109 batch 0 loss 0.313618 acc 0.937500\n",
      "Validation accuracy: 0.909317\n",
      "Epoch 110 batch 0 loss 0.313698 acc 0.937500\n",
      "Epoch 111 batch 0 loss 0.313521 acc 0.937500\n",
      "Epoch 112 batch 0 loss 0.314075 acc 0.937500\n",
      "Epoch 113 batch 0 loss 0.313435 acc 0.937500\n",
      "Epoch 114 batch 0 loss 0.313213 acc 0.937500\n",
      "Epoch 115 batch 0 loss 0.309689 acc 0.937500\n",
      "Epoch 116 batch 0 loss 0.309261 acc 0.937500\n",
      "Epoch 117 batch 0 loss 0.309138 acc 0.937500\n",
      "Epoch 118 batch 0 loss 0.308952 acc 0.937500\n",
      "Epoch 119 batch 0 loss 0.308658 acc 0.937500\n",
      "Validation accuracy: 0.911809\n",
      "Epoch 120 batch 0 loss 0.308874 acc 0.937500\n",
      "Epoch 121 batch 0 loss 0.308772 acc 0.937500\n",
      "Epoch 122 batch 0 loss 0.309744 acc 0.937500\n",
      "Epoch 123 batch 0 loss 0.309721 acc 0.937500\n",
      "Epoch 124 batch 0 loss 0.307506 acc 0.937500\n",
      "Epoch 125 batch 0 loss 0.308354 acc 0.937500\n",
      "Epoch 126 batch 0 loss 0.308191 acc 0.937500\n",
      "Epoch 127 batch 0 loss 0.308072 acc 0.937500\n",
      "Epoch 128 batch 0 loss 0.307868 acc 0.937500\n",
      "Epoch 129 batch 0 loss 0.307581 acc 0.937500\n",
      "Validation accuracy: 0.910812\n",
      "Epoch 130 batch 0 loss 0.308417 acc 0.937500\n",
      "Epoch 131 batch 0 loss 0.307909 acc 0.937500\n",
      "Epoch 132 batch 0 loss 0.307653 acc 0.937500\n",
      "Epoch 133 batch 0 loss 0.307608 acc 0.937500\n",
      "Epoch 134 batch 0 loss 0.307222 acc 0.937500\n",
      "Epoch 135 batch 0 loss 0.306732 acc 0.937500\n",
      "Epoch 136 batch 0 loss 0.306573 acc 0.937500\n",
      "Epoch 137 batch 0 loss 0.306338 acc 0.937500\n",
      "Epoch 138 batch 0 loss 0.306231 acc 0.937500\n",
      "Epoch 139 batch 0 loss 0.306040 acc 0.937500\n",
      "Validation accuracy: 0.911310\n",
      "Epoch 140 batch 0 loss 0.305829 acc 0.937500\n",
      "Epoch 141 batch 0 loss 0.305391 acc 0.937500\n",
      "Epoch 142 batch 0 loss 0.304732 acc 0.937500\n",
      "Epoch 143 batch 0 loss 0.303893 acc 0.937500\n",
      "Epoch 144 batch 0 loss 0.304325 acc 0.937500\n",
      "Epoch 145 batch 0 loss 0.303702 acc 0.937500\n",
      "Epoch 146 batch 0 loss 0.303384 acc 0.937500\n",
      "Epoch 147 batch 0 loss 0.303337 acc 0.937500\n",
      "Epoch 148 batch 0 loss 0.302536 acc 0.937500\n",
      "Epoch 149 batch 0 loss 0.302887 acc 0.937500\n",
      "Validation accuracy: 0.911310\n",
      "Epoch 150 batch 0 loss 0.302872 acc 0.937500\n",
      "Epoch 151 batch 0 loss 0.303187 acc 0.937500\n",
      "Epoch 152 batch 0 loss 0.301914 acc 0.937500\n",
      "Epoch 153 batch 0 loss 0.302339 acc 0.937500\n",
      "Epoch 154 batch 0 loss 0.303278 acc 0.937500\n",
      "Epoch 155 batch 0 loss 0.301439 acc 0.937500\n",
      "Epoch 156 batch 0 loss 0.300931 acc 0.937500\n",
      "Epoch 157 batch 0 loss 0.301618 acc 0.937500\n",
      "Epoch 158 batch 0 loss 0.301518 acc 0.937500\n",
      "Epoch 159 batch 0 loss 0.301472 acc 0.937500\n",
      "Validation accuracy: 0.911310\n",
      "Epoch 160 batch 0 loss 0.301149 acc 0.937500\n",
      "Epoch 161 batch 0 loss 0.300894 acc 0.937500\n",
      "Epoch 162 batch 0 loss 0.300641 acc 0.937500\n",
      "Epoch 163 batch 0 loss 0.299609 acc 0.937500\n",
      "Epoch 164 batch 0 loss 0.299573 acc 0.937500\n",
      "Epoch 165 batch 0 loss 0.297648 acc 0.937500\n",
      "Epoch 166 batch 0 loss 0.297812 acc 0.937500\n",
      "Epoch 167 batch 0 loss 0.297652 acc 0.937500\n",
      "Epoch 168 batch 0 loss 0.297935 acc 0.937500\n",
      "Epoch 169 batch 0 loss 0.297650 acc 0.937500\n",
      "Validation accuracy: 0.911310\n",
      "Epoch 170 batch 0 loss 0.297291 acc 0.937500\n",
      "Epoch 171 batch 0 loss 0.296955 acc 0.937500\n",
      "Epoch 172 batch 0 loss 0.296595 acc 0.937500\n",
      "Epoch 173 batch 0 loss 0.296455 acc 0.937500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174 batch 0 loss 0.296315 acc 0.937500\n",
      "Epoch 175 batch 0 loss 0.296138 acc 0.937500\n",
      "Epoch 176 batch 0 loss 0.295759 acc 0.937500\n",
      "Epoch 177 batch 0 loss 0.295540 acc 0.937500\n",
      "Epoch 178 batch 0 loss 0.293428 acc 0.937500\n",
      "Epoch 179 batch 0 loss 0.293279 acc 0.937500\n",
      "Validation accuracy: 0.912307\n",
      "Epoch 180 batch 0 loss 0.293060 acc 0.937500\n",
      "Epoch 181 batch 0 loss 0.292918 acc 0.937500\n",
      "Epoch 182 batch 0 loss 0.292046 acc 0.937500\n",
      "Epoch 183 batch 0 loss 0.291692 acc 0.937500\n",
      "Epoch 184 batch 0 loss 0.291389 acc 0.937500\n",
      "Epoch 185 batch 0 loss 0.290808 acc 0.937500\n",
      "Epoch 186 batch 0 loss 0.290092 acc 0.937500\n",
      "Epoch 187 batch 0 loss 0.289793 acc 0.937500\n",
      "Epoch 188 batch 0 loss 0.289463 acc 0.937500\n",
      "Epoch 189 batch 0 loss 0.289202 acc 0.937500\n",
      "Validation accuracy: 0.914798\n",
      "Epoch 190 batch 0 loss 0.288935 acc 0.937500\n",
      "Epoch 191 batch 0 loss 0.288602 acc 0.937500\n",
      "Epoch 192 batch 0 loss 0.288231 acc 0.937500\n",
      "Epoch 193 batch 0 loss 0.288398 acc 0.937500\n",
      "Epoch 194 batch 0 loss 0.287257 acc 0.937500\n",
      "Epoch 195 batch 0 loss 0.286478 acc 0.937500\n",
      "Epoch 196 batch 0 loss 0.286233 acc 0.937500\n",
      "Epoch 197 batch 0 loss 0.285685 acc 0.937500\n",
      "Epoch 198 batch 0 loss 0.286460 acc 0.937500\n",
      "Epoch 199 batch 0 loss 0.285985 acc 0.937500\n",
      "Validation accuracy: 0.915296\n"
     ]
    }
   ],
   "source": [
    "protoNNTrainer.train(BATCH_SIZE, NUM_EPOCHS, x_train, x_test, y_train, y_test, printStep=600, valStep=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-30T09:09:00.026Z"
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T10:25:13.469355Z",
     "start_time": "2019-06-30T10:25:13.447362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy tensor(0.9153, dtype=torch.float64)\n",
      "Model size constraint (Bytes):  78240\n",
      "Number of non-zeros:  19560\n",
      "Actual model size:  78240\n",
      "Actual non-zeros:  16368\n"
     ]
    }
   ],
   "source": [
    " x_, y_= torch.Tensor(x_test), torch.Tensor(y_test)\n",
    "logits = protoNNObj.forward(x_)\n",
    "_, predictions = torch.max(logits, dim=1)\n",
    "_, target = torch.max(y_, dim=1)\n",
    "acc, count = protoNNTrainer.accuracy(predictions, target)\n",
    "W, B, Z, gamma  = protoNNObj.getModelMatrices()\n",
    "matrixList = [W, B, Z]\n",
    "matrixList = [x.detach().numpy() for x in matrixList]\n",
    "sparcityList = [SPAR_W, SPAR_B, SPAR_Z]\n",
    "nnz, size, sparse = helper.getModelSize(matrixList, sparcityList)\n",
    "print(\"Final test accuracy\", acc)\n",
    "print(\"Model size constraint (Bytes): \", size)\n",
    "print(\"Number of non-zeros: \", nnz)\n",
    "nnz, size, sparse = helper.getModelSize(matrixList, sparcityList,\n",
    "                                        expected=False)\n",
    "print(\"Actual model size: \", size)\n",
    "print(\"Actual non-zeros: \", nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
