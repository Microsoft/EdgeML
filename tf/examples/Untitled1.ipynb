{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T09:42:13.123316Z",
     "start_time": "2018-06-28T09:42:11.250315Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import protoNNpreprocess\n",
    "import datetime\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.insert(0, '../')\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from edgeml.trainer.protoNNTrainer import ProtoNNTrainer\n",
    "from edgeml.graph.protoNN import ProtoNN\n",
    "import matplotlib.pyplot as plt\n",
    "import edgeml.utils as utils\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T09:42:16.315267Z",
     "start_time": "2018-06-28T09:42:16.301335Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def getModelSize(matrixList, sparcityList, expected=True, bytesPerVar=4):\n",
    "    '''\n",
    "    expected: Expected size according to the parameters set. The number of\n",
    "              zeros could actually be more than the applied sparsity constraint.\n",
    "    '''\n",
    "    nnzList, sizeList, isSparseList = [], [], []\n",
    "    hasSparse = False\n",
    "    for i in range(len(matrixList)):\n",
    "        A, s = matrixList[i], sparcityList[i]\n",
    "        assert A.ndim == 2\n",
    "        # 's - sparsity factor' should be between 0 and 1.\n",
    "        assert s >= 0\n",
    "        assert s <= 1\n",
    "        nnz, size, sparse = utils.countnnZ(A, s, bytesPerVar=bytesPerVar)\n",
    "        nnzList.append(nnz)\n",
    "        sizeList.append(size)\n",
    "        hasSparse = (hasSparse or sparse)\n",
    "\n",
    "    totalnnZ = np.sum(nnzList)\n",
    "    totalSize = np.sum(sizeList)\n",
    "    #By default, go into this part, fails only when the bytesPerVar need to be changed or the sparsity factor.\n",
    "    if expected:\n",
    "        return totalnnZ, totalSize, hasSparse\n",
    "\n",
    "    numNonZero = 0\n",
    "    totalSize = 0\n",
    "    hasSparse = False\n",
    "    for i in range(len(matrixList)):\n",
    "        A, s = matrixList[i], sparcityList[i]\n",
    "        numNonZero_ = np.count_nonzero(A)\n",
    "        numNonZero += numNonZero_\n",
    "        hasSparse = (hasSparse or (s < 0.5))\n",
    "        if s <= 0.5:\n",
    "            totalSize += numNonZero_ * 2 * bytesPerVar\n",
    "        else:\n",
    "            totalSize += A.size* bytesPerVar\n",
    "    return numNonZero, totalSize, hasSparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T09:43:05.628407Z",
     "start_time": "2018-06-28T09:43:05.619176Z"
    }
   },
   "outputs": [],
   "source": [
    "def loadData(dataDir):\n",
    "    train = np.load(dataDir + '/train.npy')\n",
    "    test = np.load(dataDir + '/test.npy')\n",
    "\n",
    "    dataDimension = int(train.shape[1]) - 1\n",
    "    x_train = train[:, 1:dataDimension + 1]\n",
    "    y_train_ = train[:, 0]\n",
    "    x_test = test[:, 1:dataDimension + 1]\n",
    "    y_test_ = test[:, 0]\n",
    "\n",
    "    #numClasses = max(y_train_) - min(y_train_) + 1\n",
    "    #numClasses = max(numClasses, max(y_test_) - min(y_test_) + 1)\n",
    "    #numClasses = int(numClasses)\n",
    "\n",
    "    #To use as a regressor.\n",
    "    numClasses = 1\n",
    "\n",
    "    # mean-var normalization.\n",
    "    mean = np.mean(x_train, 0)\n",
    "    std = np.std(x_train, 0)\n",
    "    std[std[:] < 0.000001] = 1\n",
    "    x_train = (x_train - mean) / std\n",
    "    x_test = (x_test - mean) / std\n",
    "\n",
    "    print (\"Inside loadData.\")\n",
    "    print (\"Mean : \",mean)\n",
    "    print (\"Std  : \",std)\n",
    "\n",
    "    #print (\"Xtrain : \",x_train[:5,:])\n",
    "    #print (\"Xtrain : \",x_test[:5,:])\n",
    "\n",
    "    \"\"\"\n",
    "    # one hot y-train\n",
    "    lab = y_train_.astype('uint8')\n",
    "    lab = np.array(lab) - min(lab)\n",
    "    lab_ = np.zeros((x_train.shape[0], numClasses))\n",
    "    lab_[np.arange(x_train.shape[0]), lab] = 1\n",
    "    y_train = lab_\n",
    "\n",
    "    # one hot y-test\n",
    "    lab = y_test_.astype('uint8')\n",
    "    lab = np.array(lab) - min(lab)\n",
    "    lab_ = np.zeros((x_test.shape[0], numClasses))\n",
    "    lab_[np.arange(x_test.shape[0]), lab] = 1\n",
    "    y_test = lab_\n",
    "    \"\"\"\n",
    "    # Don's original piece of line.\n",
    "    #return dataDimension, numClasses, x_train, y_train, x_test, y_test\n",
    "\n",
    "    return dataDimension , numClasses, x_train, y_train_.reshape((-1,1)), x_test, y_test_.reshape((-1,1)),mean,std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T09:43:28.544988Z",
     "start_time": "2018-06-28T09:43:28.506887Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -dir DATA_DIR [-p PROJDIM] [-np NUM_PROTO]\n",
      "                             [-g GAMMA] [-e NUM_EPOCHS] [-lr LEARNINGRATE]\n",
      "                             [-b BATCHSIZE] [-rW RW] [-rB RB] [-rZ RZ]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -dir/--data_dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main(**kwargs):\n",
    "    # -----------------\n",
    "    # Configuration\n",
    "    # -----------------\n",
    "    #Get the directory path, as a command line argument.\n",
    "\n",
    "    args = protoNNpreprocess.getArgs()\n",
    "    DATA_DIR = args.data_dir\n",
    "\n",
    "    PROJECTION_DIM = args.projDim\n",
    "    NUM_PROTOTYPES = args.num_proto\n",
    "    GAMMA = args.gamma\n",
    "\n",
    "    REG_W = args.rW\n",
    "    REG_B = args.rB\n",
    "    REG_Z = args.rZ\n",
    "\n",
    "    # 1.0 implies dense matrix.\n",
    "    SPAR_W = 1.0\n",
    "    SPAR_B = 1.0\n",
    "    SPAR_Z = 1.0\n",
    "    batchSize = args.batchSize\n",
    "\n",
    "    LEARNING_RATE = args.learningRate\n",
    "    NUM_EPOCHS = args.num_epochs\n",
    "    # -----------------\n",
    "    # End configuration\n",
    "    # -----------------\n",
    "\n",
    "    #if GAMMA is None:\n",
    "    #else:\n",
    "#        gamma = GAMMA\n",
    "#        W, B = None, None\n",
    "\n",
    "    out = loadData(DATA_DIR)\n",
    "    dataDimension = out[0]\n",
    "    numClasses = out[1]\n",
    "    x_train, y_train = out[2], out[3]\n",
    "    x_test, y_test = out[4], out[5]\n",
    "    print(\"Using median heuristc to estimate gamma\")\n",
    "    centers , gamma, W, B = utils.medianHeuristic(x_train, PROJECTION_DIM,\n",
    "                                        NUM_PROTOTYPES,W_init=np.eye(PROJECTION_DIM))\n",
    "    #print (\"gamma : \",gamma)\n",
    "    #gamma =  0.0156096\n",
    "    print (\"Before run : \",np.linalg.norm(B,ord=\"fro\"))\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, dataDimension], name='X')\n",
    "    Y = tf.placeholder(tf.float32, [None, numClasses], name='Y')\n",
    "\n",
    "    protoNN = ProtoNN(dataDimension, PROJECTION_DIM,\n",
    "                      NUM_PROTOTYPES, numClasses,\n",
    "                      gamma,W=W,B=B)\n",
    "\n",
    "    trainer = ProtoNNTrainer(DATA_DIR,protoNN, REG_W, REG_B, REG_Z,\n",
    "                             SPAR_W, SPAR_B, SPAR_Z,\n",
    "                             LEARNING_RATE, X, Y,lossType='l2')\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.group(tf.initialize_all_variables(),\n",
    "                      tf.initialize_variables(tf.local_variables())))\n",
    "\n",
    "    ndict = trainer.train(DATA_DIR,batchSize, NUM_EPOCHS, sess, x_train, x_test, y_train, y_test,\n",
    "                  DATA_DIR,printStep=200)\n",
    "    acc = sess.run(protoNN.accuracy, feed_dict={X: x_test, Y:y_test})\n",
    "    W, B, Z, _ = protoNN.getModelMatrices()\n",
    "    #print (\"W : \",W)\n",
    "    matrixList = sess.run([W, B, Z])\n",
    "    sparcityList = [SPAR_W, SPAR_B, SPAR_Z]\n",
    "    nnz, size, sparse = getModelSize(matrixList, sparcityList)\n",
    "    print(\"Final test accuracy\", acc)\n",
    "    print(\"Model size constraint (Bytes): \", size)\n",
    "    print(\"Number of non-zeros: \", nnz)\n",
    "    nnz, size, sparse = getModelSize(matrixList, sparcityList, expected=False)\n",
    "    print(\"Actual model size: \", size)\n",
    "    print(\"Actual non-zeros: \", nnz)\n",
    "    '''\n",
    "    #Save the value of the 'Gamma' in the dictionary.\n",
    "    #ndict[\"g\"] = gamma\n",
    "    #B : num_prototypes.\n",
    "    print (\"Prototypes (B) : \",matrixList[1].shape)\n",
    "    #Z : what it predicts.\n",
    "    print (\"Z : \",matrixList[2].shape)\n",
    "    #print (\"Z : \",matrixList[2])\n",
    "    #(np.save(\"B.npy\",matrixList[1]))\n",
    "    #print (\"B : \",matrixList[1])\n",
    "    print (\"After run : \",np.linalg.norm(matrixList[1],ord=\"fro\"))\n",
    "    pd.DataFrame(matrixList[1]).to_csv(\"B.csv\")\n",
    "    pd.DataFrame(matrixList[2]).to_csv(\"Z.csv\")\n",
    "    B = pd.DataFrame(matrixList[1])\n",
    "    print (\"W : \",matrixList[0])\n",
    "    '''\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
